{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from transformers import (AutoModelForMaskedLM, AutoTokenizer, BertConfig,\n",
    "                          BertTokenizer, TFBertModel)\n",
    "import transformers\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "max_len=160\n",
    "num_tags=2\n",
    "\n",
    "split_df=pd.read_csv('DataSet/QDS-Dataset1_Annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.821191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.763740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>976.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  4351.000000\n",
       "mean    108.821191\n",
       "std     104.763740\n",
       "min       2.000000\n",
       "25%      24.000000\n",
       "50%      79.000000\n",
       "75%     158.000000\n",
       "max     976.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split by sentence\n",
    "X=' '.join(split_df['Word'].values)\n",
    "X=X.split(' . ')\n",
    "\n",
    "y=' '.join(split_df['label'].values)\n",
    "y=y.split(' 999 ')\n",
    "y=[label.split(' ') for label in y]\n",
    "\n",
    "# print(np.array(X[:3])) # lets take a look at the X \n",
    "                       # here i hide the output because the dataset is private\n",
    "\n",
    "display(pd.DataFrame([len(x) for x in X]).describe())  \n",
    "pd.DataFrame([len(x) for x in X]).plot(kind='hist',bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data,max_len=64):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"cambridgeltl/BioRedditBERT-uncased\")\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        data,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True,\n",
    "        pad_to_max_length=True,\n",
    "        return_tensors=\"tf\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    return np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "\n",
    "# tokenize X\n",
    "X=tokenize_data(X,max_len=max_len)\n",
    "\n",
    "# train test split by sentence\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# padding labels\n",
    "y_train_pad = tf.keras.preprocessing.sequence.pad_sequences(y_train, \n",
    "                                                            padding=\"post\",\n",
    "                                                            maxlen=max_len,\n",
    "                                                            value=num_tags) # we use a different lable for padding tags\n",
    "y_test_pad = tf.keras.preprocessing.sequence.pad_sequences(y_test, \n",
    "                                                            padding=\"post\",\n",
    "                                                            maxlen=max_len,\n",
    "                                                            value=num_tags) # we use a different lable for padding tags\n",
    "\n",
    "# X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at cambridgeltl/BioRedditBERT-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000287E6BCC820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000287E6BCC820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From C:\\Users\\alex.w\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 160)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 108310272 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 160, 128)          426496    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 160, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 160, 3)            387       \n",
      "=================================================================\n",
      "Total params: 108,737,155\n",
      "Trainable params: 426,883\n",
      "Non-trainable params: 108,310,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load bert\n",
    "def bert(num_tags=2,max_len=64):\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len), dtype=tf.int32, name=\"input_ids\")\n",
    "\n",
    "    embedding = transformers.TFBertModel.from_pretrained(\"cambridgeltl/BioRedditBERT-uncased\")\n",
    "    embedding.trainable = False    # we dont want to train embedding\n",
    "\n",
    "    sequence_output = embedding(input_ids)\n",
    "\n",
    "    bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(sequence_output[0])\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(bi_lstm)\n",
    "    output = tf.keras.layers.Dense(num_tags, activation=\"softmax\")(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_ids], outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = bert(num_tags+1,max_len) # num of true tag + 1 (padding tag)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1/1 [==============================] - 42s 42s/step - loss: 1.1681\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.1588\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.0889\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0759\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0622\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0507\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0477\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0476\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.0421\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.0355\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "batch_size=128\n",
    "\n",
    "# we just want to use a small part of the data to test our code\n",
    "X_train=X_train[:5]\n",
    "y_train_pad=y_train_pad[:5]\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train_pad.reshape(y_train_pad.shape[0], y_train_pad.shape[1], 1),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.1204395e-01, 2.0236671e-02, 4.6771944e-01],\n",
       "        [5.2603412e-01, 1.8217130e-02, 4.5574871e-01],\n",
       "        [4.5599598e-01, 1.6974175e-02, 5.2702981e-01],\n",
       "        ...,\n",
       "        [8.8739040e-04, 6.7935907e-04, 9.9843329e-01],\n",
       "        [1.0778067e-03, 8.9960301e-04, 9.9802256e-01],\n",
       "        [1.9969638e-03, 2.2569208e-03, 9.9574608e-01]],\n",
       "\n",
       "       [[6.0074025e-01, 3.7279062e-02, 3.6198071e-01],\n",
       "        [7.8683174e-01, 2.6833449e-02, 1.8633489e-01],\n",
       "        [5.8251339e-01, 2.0355290e-02, 3.9713123e-01],\n",
       "        ...,\n",
       "        [8.8784593e-04, 6.7776430e-04, 9.9843436e-01],\n",
       "        [1.0796717e-03, 8.9706603e-04, 9.9802327e-01],\n",
       "        [2.0049000e-03, 2.2584354e-03, 9.9573660e-01]],\n",
       "\n",
       "       [[6.4482647e-01, 2.2968255e-02, 3.3220536e-01],\n",
       "        [6.2293416e-01, 1.3461519e-02, 3.6360425e-01],\n",
       "        [6.6157883e-01, 1.1233499e-02, 3.2718763e-01],\n",
       "        ...,\n",
       "        [9.0898294e-04, 6.7134260e-04, 9.9841964e-01],\n",
       "        [1.1050291e-03, 8.8552956e-04, 9.9800950e-01],\n",
       "        [2.0515164e-03, 2.2350606e-03, 9.9571347e-01]],\n",
       "\n",
       "       [[4.0153819e-01, 1.3673045e-02, 5.8478874e-01],\n",
       "        [4.1620624e-01, 1.1548779e-02, 5.7224500e-01],\n",
       "        [4.9272162e-01, 9.3924990e-03, 4.9788585e-01],\n",
       "        ...,\n",
       "        [8.8654907e-04, 6.6936057e-04, 9.9844414e-01],\n",
       "        [1.0760088e-03, 8.8678877e-04, 9.9803716e-01],\n",
       "        [1.9928033e-03, 2.2409377e-03, 9.9576628e-01]],\n",
       "\n",
       "       [[3.3876958e-01, 1.1796825e-02, 6.4943361e-01],\n",
       "        [4.8084682e-01, 8.3103850e-03, 5.1084280e-01],\n",
       "        [4.6915457e-01, 9.0121133e-03, 5.2183336e-01],\n",
       "        ...,\n",
       "        [8.9113449e-04, 6.6431443e-04, 9.9844462e-01],\n",
       "        [1.0808549e-03, 8.8108180e-04, 9.9803811e-01],\n",
       "        [2.0067010e-03, 2.2400951e-03, 9.9575317e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre=model.predict(X_test[:5])\n",
    "y_pre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}